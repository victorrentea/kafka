spring.application.name: app

logging:
  pattern:
    console: "%d{HH:mm:ss.SSS} [%20.20t] <%-3X{traceId}> %clr(%-5level %-30.30logger{29}) - %msg%n"
  level:
    org.apache.kafka.clients.producer.ProducerConfig: warn
    org.apache.kafka.clients.consumer.ConsumerConfig: warn
    org.apache.kafka.clients.admin.AdminClientConfig: warn
    org.apache.kafka.common.metrics.Metrics: warn
    org.apache.kafka.streams.StreamsConfig: warn
server:
  port: 8080
management.endpoints.web.exposure.include: "*"
inbox.time.window.ms: 10000
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: victor.training.kafka.intro.Event.Serializer
      properties:
        interceptor.classes: victor.training.kafka.interceptor.ProducerTraceIdInterceptor
    consumer:
      group-id: app
      properties:
        spring.json.trusted.packages: victor.*
        session.timeout.ms: 15000 # default: 45s - no heartbeats from consumer => considered dead. see also heartbeat.interval.ms=3s default
        max.poll.interval.ms: 15000 # default: 5m - max time between polls. Affects long processing time of a message
#        max.poll.records: 1 #default: 500

        enable.auto.commit: false # default: true = commit offsets automatically even if messages are not yet processed
#        auto.commit.interval.ms: 1000 # default: 5000

        interceptor.classes: victor.training.kafka.interceptor.ConsumerPollAckInterceptor
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: victor.training.kafka.intro.Event.Deserializer
    listener:
      concurrency: 2 # number of threads=consumers per topic of this machine

decorator:
  datasource:
    p6spy:
      multiline: false
      log-format: "%(executionTime) ms|%(category)|connection %(connectionId)|%(sqlSingleLine)"
      # ignore the query polling the inbox
      log-filter.pattern: "^(?!.*from inbox i1_0 where i1_0.status='PENDING').*$"