spring.application.name: app

logging:
  pattern:
    console: "%d{HH:mm:ss.SSS} [%20.20t] <%-3X{traceId}> %clr(%-5level %-30.30logger{29}) - %msg%n"
  level:
    org.apache.kafka.clients.producer.ProducerConfig: warn
    org.apache.kafka.clients.consumer: warn
    org.apache.kafka.clients.admin.AdminClientConfig: warn
    org.apache.kafka.common.metrics.Metrics: warn
    org.apache.kafka.streams.StreamsConfig: warn
    p6spy: warn #  disable sql log when ran by schedulers
    root: info
server:
  port: 8080
management.endpoints.web.exposure.include: "*"

spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: victor.training.kafka.intro.Event$Serializer
      properties:
        interceptor.classes: victor.training.kafka.interceptor.ProducerTraceIdInterceptor
    #      acks: 0 # producer does not wait for broker ack = fire and forget; default =1;
    consumer:
      group-id: app
      properties:
        spring.json.trusted.packages: victor.*
        session.timeout.ms: 15000 # default: 45s - no heartbeats from consumer => considered dead. see also heartbeat.interval.ms=3s default
        max.poll.interval.ms: 15000 # =15s (default=5m) = max time between polls. Affects long processing time of a message
        interceptor.classes: victor.training.kafka.interceptor.ConsumerPollAckInterceptor
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: victor.training.kafka.intro.Event$Deserializer
    listener: #spring-kafka
      concurrency: 2 # number of threads=consumer instances per topic of this machine
#      ack-mode: batch (default)
#      ack-mode: record (cel mai sigur, dar intens pe broker)

#      ack-mode: time/count/time_count
#      ack-time: 3s
#      ack-count: 3s

#      ack-mode: manual #Acknowledgement.acknowledge()
      # WARNING: commiting offset 7 => commit all before that
#      type: batch # bulk-process

  datasource: # external standalone DB instead of embedded one
    url: jdbc:h2:tcp://localhost:9093/~/test
    driver-class-name: org.h2.Driver
    username: sa
    password: sa
  sql:
    init:
      mode: always #schema.sql
  jpa:
    defer-datasource-initialization: true #runs after hibernate creates DB
    generate-ddl: true


decorator:
  datasource:
    p6spy:
      multiline: false
      log-format: "%(executionTime) ms|%(category)|connection %(connectionId)|%(sqlSingleLine)"
      log-filter.pattern: "^(?!.*from inbox i1_0 where i1_0.status='PENDING').*$" # ignore the poller


scheduler-workers:
  core-pool-size: 4
  max-pool-size: ${scheduler-workers.core-pool-size}
  queue-capacity: 0
  thread-name-prefix: schedwork-